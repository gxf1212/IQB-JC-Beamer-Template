# Chapter 6 QSAR and Machine Learning Predictors

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/dad37edb2753413be398e986c808192276fb91660dce4099102f6aab7eceb557.jpg)

Philipe Oliveira Fernandes and Vinicius Gonçalves Maltarollo

Abstract This chapter delves into the fundamental principles and applications of quantitative structure-activity relationship (QSAR) and machine learning (ML)-based predictors in the realm of drug design and chemical biology. QSAR establishes a quantitative relationship between the chemical structure of molecules and their biological activities or physicochemical properties. The evolution of QSAR from its first reports to its modern applications was covered comprising the theoretical foundations, encompassing descriptors, mathematical models (followed by brief examples of ML applied to this field), and statistical validation techniques employed in QSAR analysis. Interestingly, many recognized and accepted good practices and validation protocols align with OECD guidelines for QSAR applications for regulatory purposes. In this sense, notably, the QSAR field became important outside of the academic boundaries. Additionally, this chapter discusses current challenges and emerging trends in QSAR research, including the incorporation of machine learning algorithms and big data analytics for enhanced predictive accuracy and applicability. Overall, this chapter serves as a comprehensive guide for researchers and practitioners in understanding and leveraging QSAR as a pivotal tool in rational drug design and chemical biology.

Keywords QSAR  $\cdot$  Machine learning  $\cdot$  Molecular descriptors  $\cdot$  OECD principles

# 1 Historical Background

The Quantitative Structure-Activity Relationship (QSAR) field was introduced when researchers tried to correlate the molecular structure of similar compounds to a specific biological activity. This process can be traced back to 1863 when Cros first reported a correlation between the toxicity of primary aliphatic alcohols and their water solubility [1], a pioneer work in this field. Another notable work from the

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/9a204abb074623d18e0e2bb3f3d59180e078f6fdaaa394cf415ceef3ddb5ce54.jpg)  
QSAR pipeline  
Fig. 6.1 Simplified process to build and validate a QSAR model

nineteenth century was the correlation between melting- and boiling points described by Edmund J. Mills in 1884 [2]. Since then, the field expanded, and in 1962, the work from Hansch et al. [3] was considered a milestone for the modern QSAR period. A relationship between phenoxyacetic acid derivatives and their biological activity as plant growth regulators was established. In this work, they reported the famous equation relating the biological activity  $(y)$  and the descriptors  $(X)$  multiplied by specific coefficients that could be interpreted as individual importance to modulate the modeled effect. In the following years, Corwin Hansch participated in two other works [4, 5] that establish the basis of QSAR modeling used today, especially the work from Fujita et al. [5] were described as a new substituent constant. Pioneering works of these using multi-parametric regression are worth mentioning to establish the structure–activity correlation. Later, the evolution of computers allowed the use of new ways of representing molecules through theoretical descriptors, and today QSAR is an inseparable part of the drug design/discovery process [6].

As a mature research field, QSAR modeling has well-defined procedures for exploring the relationship of chemical compounds to biological activity or other properties. In this sense, the model that predicts other properties than the biological activity is also called the quantitative structure–property relationship (QSPR) [7–9], and other names are used for different purposes such as quantitative structure–reactivity relationships (QSRR) [10–12] and quantitative structure–toxicity relationship (QSTR) [13–15].

The construction of a model to predict a biological activity as a function of the molecular structure is the primary goal, and it can be explained simply in four general steps (Fig. 6.1). The first one is obtaining the data set, a group of molecules with the endpoint (the biological activity or other property that will be modeled) experimentally measured. These data can be obtained by in-house assays, nevertheless, it is more common to be retrieve datasets from the literature. Later, these data should be carefully inspected to ensure their quality. Fourches et al. [16] in the paper "Trust, but verify: on the importance of chemical structure curation in cheminformatics and QSAR modeling research" discuss the errors in structural representations observed in medicinal chemistry publications and how erroneous structures and/or duplicate entries negatively influence the QSAR models, reducing their statistical power and even leading to a complete failure. This and the follow-up

# QSAR descriptors

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/a44f4c6b17c35fc09f2ef32eea062103e853c2b779c96dfcaba30633a036bfbb.jpg)  
a)

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/42a311b7e3d224ad9ca00c1af21d733c193f0cbe7956cb6c268dae29037030d8.jpg)  
b)  
Fig. 6.2 Descriptors and fingerprints. (a) Representation of the molecular descriptors classification by the information described by the class. (b) Schematic representation of a molecular fingerprint, where the molecule is compared to specific fragments, and this information is combined in a binary vector, called a fingerprint

work [17] described a pipeline to process the information to properly perform a data curation.

Later, a mathematical representation of the molecular structure should be done as a descriptor, a fingerprint, physicochemical properties, a graph, etc. A descriptor is a numerical representation of a molecule using predefined rules and it can be obtained from the molecular formula, bidimensional, or three-dimensional structure [18, 19]. A way to classify them is related to the information obtained by using the descriptor such as geometrical descriptors that reflect the 3D structure of the molecule [19] (Fig. 6.2a). Similar to a descriptor, a fingerprint is also a representation of the molecule based on specific rules, but in a vector, where each position  $(bin)$  carries a different information [20] (Fig. 6.2b).

The descriptors can be obtained from the molecular formula, bidimensional, or three-dimensional structure. Usually, the descriptors classify the QSAR model

Table 6.1 Classification of the QSAR models according to their dimensionality of the molecular descriptor  

<table><tr><td>Class</td><td>Examples of used descriptors</td></tr><tr><td>1D-QSAR</td><td>Descriptors based on global molecular properties such as pk,a, LogP, molecular weight, and others</td></tr><tr><td>2D-QSAR</td><td>Descriptors based on structural patterns such as connectivity indices, 2D pharmacophores, and molecular fragments</td></tr><tr><td>3D-QSAR</td><td>Descriptors based on noncovalent interaction fields around 3D molecular models</td></tr><tr><td>4D-QSAR</td><td>Descriptors that include multiple ligand conformations to the 3D QSAR model, where the conformations can be generated by molecular dynamics</td></tr><tr><td>5D-QSAR</td><td>Explicitly includes several induced-fit models to the 4D QSAR model</td></tr><tr><td>6D-QSAR</td><td>Adds the solvation model to the 5D QSAR model</td></tr></table>

according to their dimensionality [21, 22] (Table 6.1). For example, a 2D-QSAR model is built using descriptors calculated from the bidimensional structure of the molecules. A 3D-QSAR model uses the three-dimensional representation of a molecule, while higher-dimensional QSAR (4D, 5D, 6D, and 7D) includes multiple conformations and other structural information [23].

Once represented, the set of the endpoint vector  $(y)$  and descriptors matrix  $(X)$  representing the compounds (samples) are used to build a model, but first, they must be split into training test sets. The training set compounds are used to teach the algorithm what descriptors are important to predict a given endpoint, in other words, to tune the relationship between  $X$  and  $y$  variables; and the test set is used to validate the model built [24] (more about this process will be discussed in further sections).

QSAR modeling already has well-defined protocols and procedures to perform the application of the techniques, especially with the growing collection of biological data available in databases such as ChEMBL [25] and PubChem [26]. The work titled "Best practices for QSAR model development, validation and exploration" developed by Alexander Tropsha [24] is an important starting point to adequately build a QSAR model. Furthermore, the Organisation for Economic Co-operation and Development (OECD) [27] principles also provide valuable checkpoints that must be followed by the QSAR model for regulatory purposes.

From the Hansch [3, 4] and Fujita [5] works, the use of linear models was well adopted to build the relationships. One application example from that time is the work of Di Paolo [28] who had built QSAR models to correlate the anesthetic activity of ether derivatives. Another contemporaneous example is the one published by Hansch and Klein [29] where they explore enzyme ligand interactions applying QSAR techniques.

Over time, several QSAR methodologies have been developed and some of them are worth mentioning. The first one is the one based on the Molecular Interaction Fields (MIF) Comparative Molecular Field Analysis (CoMFA) [30, 31], Comparative Molecular Similarity Indices Analysis (CoMSIA) [32], and hologram quantitative structure-activity relationship (HQSAR) [33, 34]. These three QSAR

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/294f604d532700ad56328994e712a5695e5790ab2d7cb5264135740ccb01b283.jpg)  
a)

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/bf7f0c2f8c0894be7b27cadb132f1aa398a4a25cbc0b64870fe6af914826d007.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/cd34a06c05db78509357b70f0f9cd2910b3be92b8334159f28ce93d2e61f3ba5.jpg)  
b)  
Fig. 6.3 Different QSAR methods: (a) schematic example of the grid-box used to calculate the MIFs, a crucial step for performing CoMFA and CoMSIA QSAR. (b) Pipeline of the HQSAR process. A molecular structure is fragmented, and these portions are combined into an array. Then, it is correlated to the biological activity using a PLS model

methodologies were successfully used in the field and they became a product implemented in the SYBYL software, commercialized by Tripos Inc.

The CoMFA QSAR is based on the correlation of the steric and electrostatic fields around the molecule and its biological activity. These two fields are calculated using a virtual probe atom (usually a  $\mathfrak{sp}^3\mathbf{C}^+$  atom) to model the stereochemical interactions by the Lenard-Jones potential and to model the electrostatic interactions by the Coulombic potential in specific x, y, z coordinates points into a lattice intersection (also known as the grid box) (Fig. 6.3a). These two sterical and electrostatic MIFs in the absence of a molecular target knowledge could be interpreted as "the negative" of ligand-receptor representation, giving insights for molecular optimization aiming to increase the potency of novel compounds. Due to the three-dimensional requirements and the need to analyze all compounds in the same position, molecular

alignment is a key step to building a CoMFA model. A PLS regression is done using the energy calculated from these fields in each point of the grid  $(X)$  and the endpoint to be modeled (usually, a biological activity,  $y$ ) [30]. Similarly, the CoMSIA QSAR is based on the same principles of the CoMFA but computing similarity indices at each point of the same grid, related to steric, electrostatic, and hydrophobic potentials obtained by a Gaussian-type function. Also, the PLS regression is used in the CoMSIA methodology [32].

Both CoMFA and CoMSIA are dependent on the three-dimensional structure of the compounds and their alignment and, therefore are considered 3D-QSAR methods. The HQSAR was an alternative to work with bidimensional structures, using structural fragments of a set of molecules (Fig. 6.3b). This is a proprietary QSAR method implemented by Tripos in the SYBYL platform [33]. In this methodology the molecular structure is described as a hologram iteratively generated with a fingerprint composed of molecular fragments built from each molecule structure. Then, the PLS regression is applied to generate the QSAR model. Despite the evolution of the QSAR field and the popularity of machine learning-based QSAR, CoMFA, CoMSIA, and HQSAR are still used in drug design campaigns [35-40].

The QSAR field is continuously growing through the development of new methods and applications. Since 2007 more than 1000 relevant articles have been published annually [41]. Machine learning methods (see Chap. 4) have significantly advanced QSAR research by enabling the understanding of complex relationships not observed by linear models. This evolution did not just happen in the academia, but today QSAR are valuable instrument in the industry [42]. For that reason, it is important to follow the best practices such as the OECD principles, and to promote high quality in QSAR modeling, those guidelines will be discussed in the next section.

# 2 OECD Principles

Usually, the QSAR modeling prioritizes optimizing the model's performance to accurately replicate experimental outcomes. This approach leads to the development of models with limited transparency and interpretability, commonly referred to as "black boxes" such as Artificial Neural Networks (ANN), algorithms inspired by the natural neural networks [43]. An extensive review of ANN-based algorithms is available in Chap. 4. Despite their utility in predictive applications, these models have not sufficiently supported the generation of reliable decisions within regulatory applications [44], due to this behavior. This behavior and other misconceptions of the QSAR modeling resulted in the publication of the "Guidance document on the validation of (quantitative)structure-activity relationships [(Q)SAR] models" by the OECD [45]. In this document, five principles to be addressed before the application of a QSAR model (Fig. 6.4) were established. This publication marked a notable advancement in the development of in silico models, emphasizing the necessity to explicitly explain the model's intended purpose, construction methodology, and

# OECD Principles

1.A defined endpoint  
2. An unambiguous algorithm  
3.A defined domain of applicability  
4.Appropriate measures of goodness-of-fit, robustness and predictivity  
5.A mechanistic interpretation, if possible

Fig. 6.4 Five principles defined by the OECD to develop and validate a QSAR model for supplementary purposes

performance metrics [44]. The following section will present in a more detailed, but not intended to be exhaustive, way.

# 2.1 A Defined Endpoint

The first principle defines that a QSAR model should have a defined endpoint and ensure the clarity of the prediction. The OECD suggests how specific an endpoint should be to ensure reliability based on the data used to build the model. It also describes examples associated with the OECD Test Guidelines such as physicochemical properties (e.g., melting point, boiling point, and water solubility) environmental fate (e.g., biodegradation, hydrolysis, and bioaccumulation), ecological effects (e.g., acute fish toxicity, and alga toxicity), and human health effects (e.g., acute oral toxicity, acute dermal toxicity, genotoxicity, and organ toxicity).

This transparency in the data is an essential requirement for regulatory agencies to validate the application of the QSAR model for a particular problem. This principle also highlighted the importance of the quality of the data obtained and recommends that ideally all QSAR should be developed using experimental data generated by a single experimental protocol. This recommendation tries to avoid the introduction of errors related to the interexperimental variability. For more details on experimental assays, please refer to Chap. 12. Cronin and Schultz [46] also suggested that variations in the analyst and the equipment could introduce noise to the biological data. When it is not possible, they recommend a training set representative of the different protocols [27].

For the endpoints that may result from diverse chemical mechanisms, QSAR models should either be developed separately for each mechanism and applied to narrowly defined classes of chemicals, or a broader QSAR relationship can be established based on shared observations across noncongeneric chemical classes with distinct mechanisms. Either approaches can be integrated, or a statistical

approach capable of simultaneous global modeling across multiple mechanisms must be employed to expand the domain of application on a broader scale.

# 2.2 An Unambiguous Algorithm

A QSAR model defines a mathematical relationship between the chemical structures and the modeled endpoint, the way this relationship is built is the algorithm of the model. For example, it can be a mathematical model, such as a linear regression or PLS, or a set of knowledge-based rules, such as a decision tree. In this sense, an unambiguous algorithm is capable of describing how the value was estimated and can be reproduced if desired.

The OECD document presents some algorithms that can perform regression, classification, or clustering (discussed in Chap.). The ability to understand how the estimation is performed contributes to the transparency of the model. Another important aspect is the distinction between the transparency of the algorithm and the ability to interpret it. For example, a linear regression can be transparent in terms of the variables' coefficients and how they are used to perform a prediction, however the variables themselves may not have an understandable physicochemical meaning based on the endpoint modeled. Two-dimensional autocorrelations and 3D Morse descriptors [47] are one example of this problem. These descriptors are widely used to build QSAR models and, despite the authors trying to give them a physical meaning, it is very shallow and hard to understand how they affect the biological activity.

Machine learning methods are more complex in comparison with traditional regression methods (such as linear regression) due to the number of mathematical operations and complex functions applied in the original descriptor values making it hard to perform a straightforward interpretation. Due to this machine learning researchers are working to develop strategies to easily interpret the variables of these so-called black-box models. Recently, Rodríguez-Pérez and Bajorath [48] described in a perspective article methodologies for better understanding the machine learning models and their individual predictions, as well the current challenges for the integration of these techniques in medicinal chemistry in this field.

# 2.3 A Defined Domain of Applicabilit

This principle relies on the necessity to establish the scope and limitations of a model, and it is based on the structure and physicochemical properties of the training set. It is expected that a model can give reliable predictions for compounds similar to those used to build the model and predictions outside this boundary are less likely to be reliable because they are extrapolations of the model.

Due to the nature of the applicability domain (AD), each model has a specific one based on the data used to train it. Also, the outcome of an AD can be categorical (e.g., yes or no) or quantitative, determining the degree of similarity between the predicted compound and the training data. There are different methods of similarity to determine if a compound falls within the AD of a model. The OECD document suggests some strategies to assess the AD, but the simplest one is observing the range of the descriptors used in the model. If the predicted compound is between the minimum and maximum values observed for each descriptor in the training set, it is inside the domain. For the model displaying few descriptors, it is easy to observe; nevertheless, it can be more complicated in complex models.

# 2.4 Appropriate Measures of Goodness-of-Fit, Robustness, and Predictivity

This OECD principle advocates for the necessity of statistical validation to ensure the predictability of the model. The OECD document divides the assessment of model performance (or statistical validation) into two stages: the internal performance (goodness-of-fit and robustness) and the external performance (predictivity). The combination of these two methods is used to analyze the model, avoiding being overfitted and underfitted. The target is a model not so simple that lacks information and is not so complex to model the noise in the data [49, 50].

The statistical validation enables comparison between different models in order to select the most predictive model. Another function of this process is to avoid "spurious" models based on correlations by chance, which are not meaningful and not predictive [51-53]. The internal validation is a measure of the model's performance using only the training set samples, which is the data used to build the model. In this sense, models that could not predict the data used in the training process could be discarded in the early stages of QSAR modeling. External validation is a way to measure the performance using compounds unseen by the model (the section validation and controls will further discuss how statistical metrics can be applied to perform these validations) and, therefore, represents an application of QSAR in actual drug discovery pipeline mimicking the prediction of compounds in commercial libraries. For that reason, it is important to assess the applicability domain to ensure a test set representative of the training set.

# 2.5 A Mechanistic Interpretation, if Possible

Historically, the first QSAR models were developed using congeneric compounds (molecules from the same chemical class with minor variations in substituents), and the activity was related to biological activities produced by the compounds'

molecular structure. The statistical methods were applied to describe the relationships and support chemical knowledge, beginning the idea of mechanistic interpretation. This OECD principle is not mandatory but is desirable, once a QSAR model is consistent if the knowledge of the chemical/toxicological process provides more credibility and acceptance of the predictions [27]. Furthermore, the interpretation of a model allows an "extra layer" of validation since the proposed mechanism could be checked according to its chemical meaning and if it is expected or not. For example, it is expected that hydrogen bond descriptors positively influence the aqueous solubility of a QSPR model [54]; otherwise, there is a high possibility that the model is not correct.

The "if possible" clause added in the principle is due to the interactive nature of the modeling process. Usually, data exploration and modeling lead to the generation and testing of a hypothesis, and a useful QSAR model may lack mechanistic interpretation due to different reasons. Nevertheless, this principle motivates the modeler to seek a mechanistic interpretation that can contribute to the understanding of the statistic validation [27].

# 3 Software and Tools

Unless you are performing your own assays, the first step to performing QSAR modeling is retrieving information from the literature. This process can be made manually by compiling published works relevant to the project or using available databases. The second approach is very common today since there are several initiatives available. One popular example is the ChEMBL database [55], a large-scale database comprising several bioactivity information. The compounds' chemical structure and detailed information about the assays are provided, comprising binding measurements, functional assays, pharmacokinetic properties, and toxicity. Besides ChEMBL there are other large databases such as PubChem [56] and BindingDB [57]. A detailed explanation of available chemical information sources is described in Chap. 2.

The next important step in the development of a QSAR model is the representation of the molecules. To obtain these representations, the molecular descriptors and/or fingerprints are calculated using specific software and web servers. A nonexhaustive list of available tools to perform descriptors/fingerprint calculations is described in Table 6.2.

Another emerging way to represent molecules is using learned embeddings such as convolutional and graph encoding to represent the molecular structures. This approach is focused on models capable of learning generalizable representations from a molecular data set. Convolutional encodings perform mathematical operations compacting the space containing the variables. One example is the work from Coley et al. [74] where atom and bond attributes were used in a convolutional neural network to represent the molecules. The authors applied the methodology to predict aqueous solubility, octanol solubility, melting point, and toxicity. Another

Table 6.2 Software and web servers available for descriptors and fingerprint calculation  

<table><tr><td>Name</td><td>Desc.</td><td>FP</td><td>Source</td></tr><tr><td>Dragon [58]</td><td>5270</td><td>1</td><td>https://www.talete.mi.it/</td></tr><tr><td>CDK [59]</td><td>275</td><td>9</td><td>https://cdk.github.io/</td></tr><tr><td>E-dragon [60]</td><td>1600</td><td>-</td><td>https://vcclab.org/lab/edragon/</td></tr><tr><td>Mold2 [61]</td><td>779</td><td>-</td><td>https://www.fda.gov/science-research/bioinformatics-tools/mold2</td></tr><tr><td>Pybel [62]</td><td>24</td><td>4</td><td>https://github.com/pybel/pybel</td></tr><tr><td>PaDEL [63]</td><td>1875</td><td>12</td><td>https://www.yapcwsoft.com/dd/padel descriptor/</td></tr><tr><td>RDKit</td><td>198</td><td>8</td><td>https://www.rdkit.org/</td></tr><tr><td>PyDPI [64]</td><td>615</td><td>7</td><td>https://pypi.org/project/pydpi/</td></tr><tr><td>Chemopy [65]</td><td>1135</td><td>7</td><td>https://github.com/ifyoungnet/Chemopy</td></tr><tr><td>ChemDes [66]</td><td>3679</td><td>59</td><td>http://www.scbdd.com/chemdes/</td></tr><tr><td>Rcpi [67]</td><td>308</td><td>10</td><td>https://bioconductor.org/packages/release/bioc/html/Rcpi.html</td></tr><tr><td>BioTriangle [68]</td><td>540</td><td>7</td><td>http://biotriangle.scbdd.com/</td></tr><tr><td>ChemSAR [69]</td><td>783</td><td>10</td><td>http://chemsar.scbdd.com/</td></tr><tr><td>Mordred [70]</td><td>1825</td><td>-</td><td>https://github.com/mordred-descriptor/mordred</td></tr><tr><td>PyBioMed [71]</td><td>775</td><td>19</td><td>https://github.com/gadsbyfly/PyBioMed</td></tr><tr><td>alvaDesc [72]</td><td>566</td><td>3</td><td>https://www.alvascience.com/alvdesc/</td></tr><tr><td>BioMedR [73]</td><td>293</td><td>13</td><td>https://github.com/wind22zhu/BioMedR</td></tr></table>

Desc. number of calculated descriptors;  $FP$  number of calculated fingerprint sets

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/72f26bf870cc6d44e7d0be7b61e57f2daa02cf84b2969c70d6418246056632f4.jpg)  
Fig. 6.5 Simplified example of a graph representation of a molecule

# Node properties:

atom type

chirality

hybridization

aromaticity

# Edge properties:

bond type

ring

stereochemistry

application of a convolutional encoding is the use of 3D information to predict protein-ligand binding affinity [75]. In the graph approach, atoms are represented as nodes and the bonds are represented by edges; both nodes and edges have associated features such as the atomic number, formal charge, and bond type (Fig. 6.5). It produces a 2D data structure; nevertheless, 3D information such as chirality or stereochemistry can be included in nodes or edges [76]. One example of graph usage is the Chemprop [77], a machine-learned package that has been used to build models to predict biological activities [78, 79], molecular properties [80, 81], and other chemical endpoints [82]. The work from McGibbon et al. [18] titled "From intuition to AI: evolution of small molecule representations in drug discovery"

provides a comprehensive approach on how the molecular representations evolved over time.

After the descriptor calculation, the division of the data set into training and test sets is a critical step to build a robust and generalizable model. This process can be performed randomly; however, a rational choice can perform better. [83-87] Generally, the aim of rational sampling is to maximize the descriptors space diversity of the training data and also maintaining the test set representative. There are many algorithms used in the QSAR context to perform this selection such as sphere exclusion, Kennard-Stone, k-means clustering, hierarchical clustering analysis (HCA), minimal test set dissimilarity, Self-Organizing Maps (SOM), and others [40, 83, 84, 88-91]. One tool available for performing it is the MASSA Algorithm, a Python software to provide an automated rational sampling using HCA, a clustering algorithm. [92] For more details on clustering algorithms, please refer to Chap. 5.

To apply the mathematical/statistical methods, a variety of options can be used. The one with more freedom is through programming, especially using Python, a popular language in cheminformatics. Several Python libraries are already available to deal with chemical structure such as RDKit [93]. Also, the Scikit-learn [94] and SciPy [95] libraries are capable of building and validating QSAR models using different statistical and machine-learning methods. For those who are not familiar with programming in Python, the TeachOpenCADD [96] is an amazing tool to learn about QSAR and other computer-aided drug design techniques. Also, platforms with a graphical user interface (GUI), such as KNIME [97], Orange [98], and Weka [99], may be used to build and validate the QSAR model. Both KNIME and Weka had available workflows for QSAR modeling in the literature [100, 101].

The SYBYL platform was a popular tool for developing different QSAR models. It is proprietary, nevertheless, there are open tools for performing QSAR modeling. There is software to perform the whole process of QSAR modeling such as the webserver 3D-QSAR.com [102]. The server can preprocess the ligand files, perform the molecular alignment, and apply the CoMFA strategy combined with PLS. Another similar example is the 3D-QSARpy [103], a Python software for building 3D-QSAR models using MIFs. The fields available are based on the Lennard-Jones potential, the Coulomb electrostatic interactions, hydrogen bond forming atoms, and hydrophobic atoms. In this software machine learning algorithms are available to build the QSAR models.

Another example is the QSARINS [104], a software to perform de build, validate, and analyze QSAR models. This program applies an MLR approach to build the model and has a series of visualization tools to perform a graphical inspection. Nevertheless, the descriptors should be calculated using external software such as the ones described in Table 6.2. Furthermore, the LQTA-QSAR software [105] allows the construction of 4D-QSAR models from molecular dynamics trajectories, building MIFs using different types of atoms, ions, and functional groups. After, the variables are selected using the Ordered Predictor Selection (OPS) algorithm [106] and then the PLS is applied to build the QSAR models. Other software for performing QSAR modeling are described in Table 6.3.

Table 6.3 Example of available software for QSAR modeling  

<table><tr><td>Name</td><td>Description</td><td>Source</td></tr><tr><td>VCCLAB [60]</td><td>A web server containing several methods to calculate molecular descriptors. It also can apply PLS and neural networks to modeling the data</td><td>https://vcclab.org/lab/</td></tr><tr><td>QSAR modeling [107]</td><td>The software uses PLS-based regression and has methods for variable selection and model validation</td><td>https://lqta.iqm.unicamp.br/</td></tr><tr><td>CORAL-QSAR/QSPR [108]</td><td>The software builds QSAR models from structures in the SMILE format using the Monte Carlo technique for function optimization</td><td>http://www.insilico.eu/coral/</td></tr><tr><td>BILIN</td><td>The software is suitable for calculating linear regression and performing some nonlinear analyses</td><td>https://www.kubinyi.de/bilin-program.html</td></tr><tr><td>BuildQSAR [109]</td><td>The software can perform the mathematical modeling, hypothesis testing, and graphics/correlation analysis</td><td>-</td></tr></table>

# 4 Validations and Controls

Statistical validation is not the same as experimental validation. For example, QSAR models are extensively validated by statistical strategies and metrics but its proof-of-concept for drug design purposes should be the designing of a new chemical entity followed by the experimental evaluation of the predicted activity/property.

# 4.1 Internal and External Validation

The early QSAR modeling relies on the division of data sets into two smaller subsets: training and test sets, usually with 80 and  $20\%$  of the total data, respectively. Of course, this proportion could be different ranging from 90/10 to 50/50.

The training set compounds are employed to teach the algorithm or to extract information to build the equation that correlates biological activity with the descriptors. However, this very same subset is often used to validate internally the ability of the QSAR model to make predictions (in this case, often called the robustness of the model). It is expected that the predictions are highly correlated with experimental data used to train the model (measured as  $\mathrm{r}^2$ ). However, the training set should be divided into smaller subsets to validate the predictions. This technique is called cross-validation (or k-fold cross-validation) and consists of a split training set  $\mathbf{k}$  times into  $\mathbf{k}$  sub-subsets, and using one subgroup for validation purposes and the remaining groups for training the model. In this sense, 5-fold and 10-fold cross-validation as well as leave-one-out (LOO) cross-validation are the most employed strategies. As the name suggests, LOO leaves one compound out of the training set, generates a model, predicts the activity for this compound, stores the predicted value, and then, returns this sample for the original training set, removes

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/b9dbfda06487d10e68625752e8167ff01184572de0dcf21f9bf910e3841a875d.jpg)  
Fig. 6.6 Validations and controls for training and test/repeated k-Fold/Leave-One-Out (LOO)

another compound, and does this set of tasks until all compounds were used for prediction. Finally, the stored predicted values are used to calculate errors of prediction and correlation coefficients (Fig. 6.6).

In contrast, 5-fold crossvalidation does this process only five times instead of leaving one single compound, this strategy leaves  $1/5$  (or  $20\%$ ) of samples out at the same time, 5 times (Fig. 6.5). Likewise, 10-fold crossvalidation does this sub-subset division 10 times, leaving  $1/10$  ( $10\%$ ) of samples out for internal validation 10 times.

Some works validate the final reported models using the strategy leave-many-out, which consists of varying the sample ratio in sub-subset division in several replicates (generally, 3 or 5 replicates), systematically to cover small and large sub-subsets of test compounds. In that sense, this strategy could evaluate the consistency of the model to keep its robustness throughout variation of sub-training and sub-test sizes and suggest that the generated model was not obtained as an artifact of a single replicate of a specific data set composition.

# 4.1.1 Regression Metrics

For regression models, there are several metrics (Table 6.4) that should be calculated to assess both robustness and predictability. Robustness could be defined as the ability to maintain its predictive performance across different data sets and is

Table 6.4 Regression metrics commonly used to validate QSAR models  

<table><tr><td>Criteria</td><td>Metrics</td></tr><tr><td>Internal Q2</td><td>Q2=1-(∑nTRi=1ŷi-ŷi)2/∑nTRi=1ŷi-ŷ)2≈1</td></tr><tr><td rowspan="4">Golbraikh and Tropsha criteria</td><td>R2=(∑nEXTi=1(ŷi-ŷ) (ŷi-ŷ) / √∑nEXTi=1(ŷi-ŷ)2 ∑nEXTi=1(ŷi-ŷ)2)2≈1</td></tr><tr><td>R02=1-(∑nEXTi=1ŷi-ŷr0)2/∑nEXTi=1ŷi-ŷ)2≈R2; R02=1-(∑nEXTi=1ŷi-ŷr0)2/∑nEXTi=1ŷi-ŷ)2≈R2</td></tr><tr><td>k=(∑nEXTi=1ŷi-ŷr0)2/∑nEXTi=1ŷi-ŷr0)≈1; k′=(∑nEXTi=1ŷi-ŷr0)2/∑nEXTi=1ŷi-ŷr0)≈k′y_i</td></tr><tr><td>R02and R02are calculated forcing the regression line to pass through the origin, k and k′ are the slope of the regression lines</td></tr><tr><td rowspan="3">External Q2 functions</td><td>Q2F1=1-(∑nEXTi=1(ŷi-ŷ)2/∑nEXTi=1ŷi-ŷr)2=1-PRESS/TSSEXT(ŷTR)</td></tr><tr><td>Q2F2=1-(∑nEXTi=1ŷi-ŷr)2/∑nEXTi=1ŷi-ŷr0)2=1-PRESS/TSSEXT(ŷEXT)</td></tr><tr><td>Q2F3=1-(∑nEXTi=1ŷi-ŷr)2/nEXT/∑nEXTi=1ŷi-ŷr0)=1-PRESS/nEXT/TSSEXT(ŷEXT)/nTR</td></tr><tr><td>Concordance correlation coefficient (CCC)</td><td>CCC=2∑nEXTi=1(yi-ŷ) (ŷi-ŷ) / ∑nEXTi=1(yi-ŷ)2+∑nEXTi=1ŷi-ŷ)2+nEXT(i-ŷ)2</td></tr><tr><td rowspan="4">Roy et al. criteria</td><td>r2m=r2(1-√r2-r02)&gt;0.5</td></tr><tr><td>r2m=(r2m+r′2m)/2</td></tr><tr><td>Δr2m=|r2m-r′2m|&lt;0.2</td></tr><tr><td>r2and r02are respectively the determination coefficients of the regression function, calculated using the experimental and the predicted data of the prediction set, forcing respectively the origin of the axis (r2) or not (r02). rm2is calculated using experimental values on the ordinate axis, using them on the abscissa</td></tr><tr><td>Root mean square error</td><td>RMSE=√∑nEXTi=1ŷi-ŷr)2/nEXT</td></tr><tr><td>Mean absolute error</td><td>MAE=∑nEXTi=1|yi-ŷ|/nEXT</td></tr></table>

TR Training set; EXT External set,  $y_{i}$  Experimental data values;  $\widehat{y}_i$  Predicted data values;  $\overline{y}$  Average of the experimental data values;  $\widehat{\overline{y}}$  Average of the predicted values

calculated using different internal validation strategies. The predictability is the predictive performance of a QSAR model for unseen new molecules (test set). For example,  $\mathbf{R}^2$ -derived metrics, such as  $\mathbf{Q}^2$  calculated with LOO or other internal validation strategy, a metric to estimate the robustness of a model. Usually, some authors report an  $\mathbf{R}^2$  (calibration coefficient) metric which is calculated with the same formula as  $\mathbf{Q}^2$  but with no internal validation. Together,  $\mathbf{R}^2$  and  $\mathbf{Q}^2$  could be

used as a guide to prevent overfitting: ideally, the difference between those two metrics should be lower than 0.3 ( $\mathbf{R}^2 - \mathbf{Q}^2 > 0.3$ ) [93, 94].

In addition, errors such as RMSE and/or MAE metrics could be calculated in both internal and external validation procedures. The Root Mean Squared Error (RMSE), derived from MSE, offers an interpretable measure by maintaining the same units as the target variable. The Mean Absolute Error (MAE), which measures the average magnitude of errors in predictions without considering their direction, provides a straightforward interpretation of prediction accuracy.

Nowadays, it is recommended that a consensus of all metrics should be used in the evaluation of a given QSAR model's quality [110]. Those metrics are  $\mathbf{Q}^2$  coefficients discussed by Consonni and colleagues [112],  $\mathrm{r}_{\mathrm{m}}^{2}$  parameters were introduced by Roy and collaborators [111], and CCC from Gramatica work [113] as well as the errors of predictions.

# 4.1.2 Classification Metrics

Usually, classification models use the amount of true positive and negative (TP and TN) as well as false-positive and -negative (FP and FN) predictions to calculate access robustness and predictivity. Those classes of predictions are commonly organized in the confusion matrix (Fig. 6.7).

<table><tr><td rowspan="2" colspan="2"></td><td colspan="2">Predicted condition</td></tr><tr><td>Predicted positive</td><td>Predicted negative</td></tr><tr><td rowspan="2">Actual condition</td><td>Positive</td><td>True positive (TP)</td><td>False negative (FN)</td></tr><tr><td>Negative</td><td>False positive (FP)</td><td>True negative (TN)</td></tr></table>

Fig. 6.7 Elements of a confusion matrix

Table 6.5 Classification metrics applied to validate classification models using the elements of the confusion matrix  

<table><tr><td>Metric</td><td>Formula</td></tr><tr><td>True Positive Rate (TPR), recall, sensitivity</td><td>TPR = 2TP/2TP+FP+FN</td></tr><tr><td>True Negative Rate (TNR), specificity, selectivity</td><td>TNR = TN/TN+FP</td></tr><tr><td>Accuracy (ACC)</td><td>ACC = TP+TN/P+N</td></tr><tr><td>Balanced Accuracy (bACC)</td><td>bACC = TPR+TNR/2</td></tr><tr><td>Matthews&#x27; correlation coefficient (MCC)</td><td>MCC = (TP × TN) - (FP × FN)/√(TP+FP)+(TP+FN)+(TN+FP)+(TN+FN)</td></tr><tr><td>F1-Score</td><td>F1 Score = 2TP/2TP+FP+FN</td></tr><tr><td>CK</td><td>CK = 2 × (TP × TN+FP × FN)/(TP+FP)(TP+FN)(TN+FP)(TN+FN)</td></tr><tr><td>Enrichment factor at X% of the screened dataset</td><td>EFX%= activatesX%/(datasetX%)/activestotal/datasettotal</td></tr></table>

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/752e30948afe518a47fea5a69eef97c008d49886fb19b51993a95aee4abd6f59.jpg)  
Fig. 6.8 Schematic example of a Receiver Operating Characteristic (ROC) Curve and the interpretation of the Area Under the ROC Curve (AUC-ROC)

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/e328fd749546b99cc3b7f80cf88a21f02f8c4d81a7f365dcd6bc2fcad5bdce72.jpg)

Among the metrics to validate classification models (Table 6.5) and quantify their performance, accuracy (ACC) is a fundamental metric that represents the proportion of correct predictions out of the total predictions made and may be the most employed one. However, accuracy alone can be misleading, especially with imbalanced data sets (a set of compounds with more samples present in one class than others). To address this, recall or true positive rate (TPR) and sensitivity or true negative rate (TNR) are also used to avoid models with rates of false positives and negative predictions. In this sense, those metrics could cover the ability of a given model to predict in each class. In the same sense, the Matthews' Correlation Coefficient (MCC) is a metric used to evaluate the performance of classification models, particularly in binary classification tasks taking into consideration all four categories of the confusion matrix: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).

Additionally, the Receiver Operating Characteristic (ROC) Curve and the Area Under the Curve (AUC) (Fig. 6.8) offer insights into the model's ability to distinguish between classes across different threshold settings, with the AUC summarizing the overall performance. While the area under the ROC curve (AUC-ROC) provides an overall assessment of the ability to distinguish between classes (active and inactive), the enrichment factor metrics and AUC-BEDROC offer information about this distinguishing ability in the initial fractions ( $X\%$  of the data set) of the

curve. Usually, authors define  $\mathrm{X\%}$  as equal to 0.5, 1.0, 2.0, 5.0, and/or  $10.0\%$ . In other words, these two metrics evaluate the protocol's ability to distinguish between molecules with the highest likelihood of being biologically active according to the probabilities of prediction of a given classification model [114-116].

As for regression models, an ensemble of all metrics from the confusion matrix as well as from ROC curves are considered the state-of-the-art analyses for the model's evaluation.

# 4.2 Applicability Domain

The applicability domain (AD) assessment is another analysis that is not properly a validation but is extremely important to ensure that external validations were performed adequately as well as predictions on unseen databases (e.g., virtual screening) are trustable or not. This importance is also highlighted and highly recommended by OECD principles for QSAR prediction rule number three. AD is a modeling step that compares the test set and/or external sets (e.g., libraries for future applications) with the training set considering their similarity in the space used to train the model. Structural similarity using fingerprints is also used for this task. In this sense, compounds similar to training set ones are considered inside the applicability domain and, therefore, predictions done to this sample could be considered trustworthy rather than just obtained by chance. In contrast, dissimilar compounds are considered outside the applicability domain and, therefore, the predictions made for this sample could be considered just a guess or random prediction from the model. There are a few methods to estimate the applicability domain of a given model such as based on the descriptor ranges, the knowledge density in the descriptors space around a query compound, or using a convergence of elements to support the prediction [117].

An interesting example was reported by Serafim and colleagues [118], discussing the implications of analyzing the applicability domain and illustrating it with an unsuccessful virtual screening campaign. In this work, hits were submitted to experimental validation and failed in this step due to the very dissimilar structures and properties in comparison to the training set of the model employed in the predictions.

# 4.3 Randomization Tests

After the internal and external validations, it is important to ensure that the observations in the models are genuine, and not an artifact of random correlation. This validation is made by shuffling the data, and it is expected that the model using these scrambled data performs worse than the original model.

Y-scrambling is a method to evaluate if the generated model was obtained by chance. In this method, a model is trained using the same training set of compounds, and the same set of descriptors but the activity (the Y property) is randomized. As expected, this new "random" model should perform worse than the original unscrambled model. In other words, correlation coefficients calculated values should be lower than acceptable thresholds of quality, and errors of prediction should be higher than acceptable. Of course, it is recommended that this task should be carried out several times, usually, reported works use from 20 to 200 runs of Y-scrambling tests.

Other metrics that should be considered in this validation are the correlation between q2 calculated with internal validation and the correlation coefficient between the original Y values and scrambled Y values. In this sense, it is expected that the degree of Y-randomization is correlated with the degree of "quality loss" (or decrease in q2, for example) of scrambled models.

There are some variations such as progressive scrambling implemented with the original CoMFA in the Sybyl package. This method progressively randomizes the Y values in distinct ranges of biological activity. For example, if a data set compound's pIC50 values range from 4 to 10, this method generates several bin windows for randomization: first, it splits the data set into six bins of 1 log unity (randomizes the pIC50 values of compounds inside that bin); then, in three bins of 2 log unities; and so on until randomizing the biological activity values in one single bin (the entire data set such as the traditional Y-scrambling).

Lastly, X-scrambling validation is usually made for classification methods since the Y value is binary (generally, 0 for inactive and 1 for actives). In this sense, X-scrambling aims to evaluate the same feature of the model (possibility to be obtained by chance) but randomizing the X variables.

# 5 Interpretation

Seeking the improvement of performance and generality, the QSAR models increase their complexity, however, this gain in complexity is only reasonable if the simpler models cannot handle the problem [119]. The prediction understanding promotes transparency and integrates with expert knowledge promoting useful insights learned by the observed patterns, and the interpretation can be made in two different ways, global and individual prediction [48] (Fig. 6.9).

The global model interpretations are related to what were the prioritized variables and how they are used to perform the predictions. A classic example of global model interpretations is linear regressions. Analyzing the coefficients in the equation, it is possible to observe how each variable contributes to the model (positively or negatively) and their magnitude. The same analogy can be applied in linear Support Vector Machine models, observing the feature weights. Tree-based algorithms are

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/84791bf6069d6f63b579a6cd123fb53efc553470174e568ce946835ac7cf134a.jpg)  
Fig. 6.9 Strategies to interpret a QSAR model. The first one is observing globally how the features impact the model, and the second one is using an individual prediction to see how the feature in the molecule impacts the prediction

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-07/0214078d-e726-44e3-bcc9-fed2e4c27070/515c1b46f179b09feb167908fb72e9dac9da8ca13bdafcd5ea36cb5aeeba4f30.jpg)

also globally interpreted in terms of information theory, estimating the magnitude of a contribution [48]. Besides the algorithm interpretation, the feature permutation is a viable and method-independent strategy for interpreting the model globally [120].

In contrast to the global interpretation are the individual predictions. This approach tries to understand what patterns and features are important in the prediction of a specific compound. Not necessarily a globally important feature will be important in the prediction of a single compound and both can be complementary. Several agnostic methods have been used to interpret individual predictions such as Locally Interpretable Model-Agnostic Explanations (LIME) [121] and Shapley Additive Explanations (SHAP) [122]. LIME generates local explanations by perturbing input features and observing how these perturbations affect the model's predictions, resulting in a contribution that explains how each feature influenced the prediction. SHAP also quantifies the contribution of each feature to the model's output but is based on the principle of Shapley values derived from cooperative game theory. The importance of each feature is accessed based on its contribution to the prediction relative to all possible feature combinations. SHAP can provide both local interpretations and global insights. The local interpretation is obtained when Shapley values are calculated for each feature to explain the contribution of that specific prediction and globally when this process is made across all predictions in the data set.

# 6 Practical Advice During QSAR Modeling

The process of modeling can be quite challenging in the first look. In summary, based on the work experience, some questions are described in Table and the answers may help guide when planning a QSAR study.

# Useful considerations during the QSAR model development

<table><tr><td>? Questions to answer when planning a QSAR modeling</td></tr><tr><td>Data collection and preprocessing</td></tr><tr><td>How were the experimental data generated? Is there a unified protocol? How to deal with these differences?</td></tr><tr><td>Is the training/test data representative in terms of protocol and terms of the descriptors used?</td></tr><tr><td>How will missing values, outliers, and redundant descriptors be handled?</td></tr><tr><td>Will the data need to be standardized or transformed?</td></tr><tr><td>Model selection</td></tr><tr><td>Which modeling techniques (e.g., linear regression, neural networks, and support vector machines) will be employed?</td></tr><tr><td>How will the model&#x27;s complexity be determined and optimized?</td></tr><tr><td>Model validation</td></tr><tr><td>What validation methods (e.g., cross-validation, external validation) will be used to assess model performance?</td></tr><tr><td>How will overfitting be addressed?</td></tr><tr><td>Interpretation and visualization</td></tr><tr><td>How will the QSAR model results be interpreted in the context of chemical and biological knowledge?</td></tr><tr><td>What visualization techniques will be utilized to aid in understanding the relationships between chemical structure and activity?</td></tr><tr><td>Application and deployment</td></tr><tr><td>How will the QSAR model be applied to predict the activity of new compounds?</td></tr><tr><td>How will the models be accessible to nonexperts?</td></tr><tr><td>What are the limitations and assumptions of the model, and how will they be communicated?</td></tr><tr><td>Iterative improvement</td></tr><tr><td>How will the pipeline be iteratively improved based on feedback and new data?</td></tr><tr><td>Are there opportunities to incorporate additional data sources or enhance modeling techniques?</td></tr></table>

# 7 Application

As examples of QSAR applications in the drug discovery field, five works published between 2023 and 2024 were described in detail. As selection criteria, the selected articles used computational techniques to identify active compounds that were experimentally validated.

Moreira-Filho et al. [123] used classification and regression machine learning models to predict the schistosomicidal activity of compounds that had not been experimentally tested. Subsequently, the prioritized compounds underwent testing on both schistosomula and adult stages of Schistosoma mansoni. Among them, four compounds demonstrated substantial activity against schistosomula, with  $50\%$  effective concentration values ranging from 9.8 to  $32.5~\mu \mathrm{M}$ , while showing no toxicity in animal and human cell lines.

A virtual screening comprising multiple computational methods was reported by Mushtaq and colleagues [124] to identify compounds with anti-interleukin-2 activity. The authors validated a molecular docking protocol and applied it in combination with pharmacophore filtering starting from a library containing 11.9 million compounds from ZINC and resulting in 24 compounds that had their activities predicted with a properly validated CoMFA model. Then, only nine compounds were submitted to experimental validation and three of them were considered promising hits due to the IL-2 inhibitory effect.

An interesting application of machine-learning-based virtual screening was reported by Barbosa et al. [125] In this work, they generated and validated kNN and Random Forest models to predict activity against Trypanosoma cruzi and used the models to screen a natural products database. After the selection of a virtual hit, they identified a plant that produced this hit as a metabolite (Cymbopogon schoenanthus), performed the isolation and identification of the selected compound, a diterpenoid called andrographolide, and tested it. As a result of the experimental validation, this compound showed  $\mathrm{IC}_{50}$  values of 29.4 and  $2.9\mu \mathrm{M}$  against trypomastigote and amastigote forms of T. cruzi and a selectivity index equal to 32, comparable with the positive control.

In 2024, Fernandes and colleagues reported a machine learning-based virtual screening [126] or discovering antibacterial compounds against methicillin-susceptible and resistant strains of Staphylococcus aureus. In this work, they generated descriptor-based QSAR classification models using several diverse machine learning methods for three data sets: one comprised of compounds with activity against susceptible strains of S. aureus; another one comprised of compounds with activity against resistant strains; and a third one comprised of compounds with activity against both strains. This last data set was very important to weigh the consensus selection of hits for experimental testing since it comprised both modeled activities. In this sense, the hit rate of models generated from this data set was higher than the other two models.

Wong et al. [127] experimentally screened 39,312 compounds against a methicillin-susceptible S. aureus strain (RN4220) as a model for antibacterial activity and against human liver carcinoma cells (HepG2), human primary skeletal muscle cells (HSkMCs), and human lung fibroblast cells (IMR-90) as models for cytotoxicity. After, they used Chemprop to train a graph neural network to predict a binary classification task for all properties (activity and toxicities). After training and validation of models, the authors screened two libraries for obtaining compounds with predicted antibacterial activity and no cytotoxic profile. Following this, potential false-positive compounds were removed using PAINS rules and undesired compounds due to reactivity, metabolic instability, and generalized toxicity were also removed by using Brenk structural alerts. Lastly, the authors selected compounds with similarity scores equal or lower than 0.5 in comparison with data set compounds. In this sense, they started with approximately 12 million compounds, and, after filtering, they selected 1261 compounds. As a strategy to interpreting the models, the authors used Monte Carlo tree searches to explore the chemical space and understand the smallest portion of a molecule responsible for their classification

as active. With this approach, it was possible to highlight important structural features responsible for predictions. Then, using the rational structural predictions they filtered the hits according to analogs that match known antibacterial classes such as quinolone, cephalosporins, and  $\beta$ -lactams, then selecting 9 compounds for experimental validations. Four of the nine tested compounds were actives reaching a  $44\%$  success rate.

This last example is not an actual application of QSAR for drug design discovery, but a free platform available for early stages ADME profile prediction [128]. The Pharmacokinetics Profiler (PhaKinPro, available at: https://phakinpro.mml.unc.edu/) is a web server with QSAR models to predict hepatic stability, microsomal half-life in sub-cellular and tissue, renal clearance, blood-brain barrier (BBB) permeability, central nervous system (CNS) activity, Caco-2 permeability, plasma protein binding, plasma half-life, microsomal intrinsic clearance, and oral bioavailability. Despite the validation metrics of each model, the predictions at the web server provide the confidence of prediction, if the compound is inside of AD or not, and the importance of molecular fragments for the prediction as the interpretation of the model.

# 8 Challenges and Perspectives

As mentioned, statistical methods and algorithms have a poor ability to handle data from different sources and, consecutively, biological data from different protocols. In that sense, ML methods emerge as promising methods to model data with noise due to the superior ability of generalization. Indeed, this task has naturally evolved since biology and chemistry joined the big data concept with large databases. However, it desired methods to ensure how the data noise affects the quality of the predictions.

Another related issue is better attention and report of imbalanced data sets for classification models and potential gaps in modeled activities for regression models. Very often, authors underreport this aspect of data sets and, of course, biased data sets produce biased models which make biased predictions. The balance between classes introduces a bias in the modeled activity. However, other sources of bias must be avoided and well reported in QSAR modeling protocols, such as structural and physicochemical biases which could be solved (or, at least, used to warn potential users of reported models) with the combination of data set characterization and proper AD definition.

Multi-task models, in other words, models with the ability to predict more than one property  $(y)$  are well established in the literature; however, authors very often report parallel individual models. Maybe, the lack of ready-to-use software with this ability and the need for coding limit the spreading of this modality of modeling. In the same way, transfer learning is a set of methods that transfer knowledge from one trained and validated model to another. Of course, both models must share mechanisms or similarities in the modeled property, for example, models to predict the binding affinity of ligands to close homolog and structurally similar enzymes. This